{"task_id": "HumanEval/16", "prompt": "\n\ndef count_distinct_characters(string: str) -> int:\n    \"\"\" Given a string, find out how many distinct characters (regardless of case) does it consist of\n    >>> count_distinct_characters('xyzXYZ')\n    3\n    >>> count_distinct_characters('Jerry')\n    4\n    \"\"\"\n", "entry_point": "count_distinct_characters", "canonical_solution": "    return len(set(string.lower()))\n", "test": "\n\nMETADATA = {\n    'author': 'jt',\n    'dataset': 'test'\n}\n\n\ndef check(candidate):\n    assert candidate('') == 0\n    assert candidate('abcde') == 5\n    assert candidate('abcde' + 'cade' + 'CADE') == 5\n    assert candidate('aaaaAAAAaaaa') == 1\n    assert candidate('Jerry jERRY JeRRRY') == 5\n", "sample_io": ["assert count_distinct_characters('xyzXYZ') == 3", "assert count_distinct_characters('Jerry') == 4"], "source_codes": [""], "responses": [""], "prompt_tokens": [0], "completion_tokens": [0], "no_of_try": 1, "is_solved": false, "language": "Python3"}
{"task_id": "HumanEval/17", "prompt": "from typing import List\n\n\ndef parse_music(music_string: str) -> List[int]:\n    \"\"\" Input to this function is a string representing musical notes in a special ASCII format.\n    Your task is to parse this string and return list of integers corresponding to how many beats does each\n    not last.\n\n    Here is a legend:\n    'o' - whole note, lasts four beats\n    'o|' - half note, lasts two beats\n    '.|' - quater note, lasts one beat\n\n    >>> parse_music('o o| .| o| o| .| .| .| .| o o')\n    [4, 2, 1, 2, 2, 1, 1, 1, 1, 4, 4]\n    \"\"\"\n", "entry_point": "parse_music", "canonical_solution": "    note_map = {'o': 4, 'o|': 2, '.|': 1}\n    return [note_map[x] for x in music_string.split(' ') if x]\n", "test": "\n\nMETADATA = {\n    'author': 'jt',\n    'dataset': 'test'\n}\n\n\ndef check(candidate):\n    assert candidate('') == []\n    assert candidate('o o o o') == [4, 4, 4, 4]\n    assert candidate('.| .| .| .|') == [1, 1, 1, 1]\n    assert candidate('o| o| .| .| o o o o') == [2, 2, 1, 1, 4, 4, 4, 4]\n    assert candidate('o| .| o| .| o o| o o|') == [2, 1, 2, 1, 4, 2, 4, 2]\n", "sample_io": ["assert parse_music('o o| .| o| o| .| .| .| .| o o') == [4, 2, 1, 2, 2, 1, 1, 1, 1, 4, 4]"], "source_codes": [""], "responses": [""], "prompt_tokens": [0], "completion_tokens": [0], "no_of_try": 1, "is_solved": false, "language": "Python3"}
{"task_id": "HumanEval/18", "prompt": "\n\ndef how_many_times(string: str, substring: str) -> int:\n    \"\"\" Find how many times a given substring can be found in the original string. Count overlaping cases.\n    >>> how_many_times('', 'a')\n    0\n    >>> how_many_times('aaa', 'a')\n    3\n    >>> how_many_times('aaaa', 'aa')\n    3\n    \"\"\"\n", "entry_point": "how_many_times", "canonical_solution": "    times = 0\n\n    for i in range(len(string) - len(substring) + 1):\n        if string[i:i+len(substring)] == substring:\n            times += 1\n\n    return times\n", "test": "\n\nMETADATA = {\n    'author': 'jt',\n    'dataset': 'test'\n}\n\n\ndef check(candidate):\n    assert candidate('', 'x') == 0\n    assert candidate('xyxyxyx', 'x') == 4\n    assert candidate('cacacacac', 'cac') == 4\n    assert candidate('john doe', 'john') == 1\n", "sample_io": ["assert how_many_times('', 'a') == 0", "assert how_many_times('aaa', 'a') == 3", "assert how_many_times('aaaa', 'aa') == 3"], "source_codes": [""], "responses": [""], "prompt_tokens": [0], "completion_tokens": [0], "no_of_try": 1, "is_solved": false, "language": "Python3"}
{"task_id": "HumanEval/19", "prompt": "from typing import List\n\n\ndef sort_numbers(numbers: str) -> str:\n    \"\"\" Input is a space-delimited string of numberals from 'zero' to 'nine'.\n    Valid choices are 'zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight' and 'nine'.\n    Return the string with numbers sorted from smallest to largest\n    >>> sort_numbers('three one five')\n    'one three five'\n    \"\"\"\n", "entry_point": "sort_numbers", "canonical_solution": "    value_map = {\n        'zero': 0,\n        'one': 1,\n        'two': 2,\n        'three': 3,\n        'four': 4,\n        'five': 5,\n        'six': 6,\n        'seven': 7,\n        'eight': 8,\n        'nine': 9\n    }\n    return ' '.join(sorted([x for x in numbers.split(' ') if x], key=lambda x: value_map[x]))\n", "test": "\n\nMETADATA = {\n    'author': 'jt',\n    'dataset': 'test'\n}\n\n\ndef check(candidate):\n    assert candidate('') == ''\n    assert candidate('three') == 'three'\n    assert candidate('three five nine') == 'three five nine'\n    assert candidate('five zero four seven nine eight') == 'zero four five seven eight nine'\n    assert candidate('six five four three two one zero') == 'zero one two three four five six'\n", "sample_io": ["assert sort_numbers('three one five') == 'one three five'"], "source_codes": [""], "responses": [""], "prompt_tokens": [0], "completion_tokens": [0], "no_of_try": 1, "is_solved": false, "language": "Python3"}
{"task_id": "HumanEval/20", "prompt": "from typing import List, Tuple\n\n\ndef find_closest_elements(numbers: List[float]) -> Tuple[float, float]:\n    \"\"\" From a supplied list of numbers (of length at least two) select and return two that are the closest to each\n    other and return them in order (smaller number, larger number).\n    >>> find_closest_elements([1.0, 2.0, 3.0, 4.0, 5.0, 2.2])\n    (2.0, 2.2)\n    >>> find_closest_elements([1.0, 2.0, 3.0, 4.0, 5.0, 2.0])\n    (2.0, 2.0)\n    \"\"\"\n", "entry_point": "find_closest_elements", "canonical_solution": "    closest_pair = None\n    distance = None\n\n    for idx, elem in enumerate(numbers):\n        for idx2, elem2 in enumerate(numbers):\n            if idx != idx2:\n                if distance is None:\n                    distance = abs(elem - elem2)\n                    closest_pair = tuple(sorted([elem, elem2]))\n                else:\n                    new_distance = abs(elem - elem2)\n                    if new_distance < distance:\n                        distance = new_distance\n                        closest_pair = tuple(sorted([elem, elem2]))\n\n    return closest_pair\n", "test": "\n\nMETADATA = {\n    'author': 'jt',\n    'dataset': 'test'\n}\n\n\ndef check(candidate):\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2]) == (3.9, 4.0)\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0]) == (5.0, 5.9)\n    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.2]) == (2.0, 2.2)\n    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0]) == (2.0, 2.0)\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1]) == (2.2, 3.1)\n\n", "sample_io": ["assert find_closest_elements([1.0, 2.0, 3.0, 4.0, 5.0, 2.2]) == (2.0, 2.2)", "assert find_closest_elements([1.0, 2.0, 3.0, 4.0, 5.0, 2.0]) == (2.0, 2.0)"], "source_codes": [""], "responses": [""], "prompt_tokens": [0], "completion_tokens": [0], "no_of_try": 1, "is_solved": false, "language": "Python3"}
{"task_id": "HumanEval/21", "prompt": "from typing import List\n\n\ndef rescale_to_unit(numbers: List[float]) -> List[float]:\n    \"\"\" Given list of numbers (of at least two elements), apply a linear transform to that list,\n    such that the smallest number will become 0 and the largest will become 1\n    >>> rescale_to_unit([1.0, 2.0, 3.0, 4.0, 5.0])\n    [0.0, 0.25, 0.5, 0.75, 1.0]\n    \"\"\"\n", "entry_point": "rescale_to_unit", "canonical_solution": "    min_number = min(numbers)\n    max_number = max(numbers)\n    return [(x - min_number) / (max_number - min_number) for x in numbers]\n", "test": "\n\nMETADATA = {\n    'author': 'jt',\n    'dataset': 'test'\n}\n\n\ndef check(candidate):\n    assert candidate([2.0, 49.9]) == [0.0, 1.0]\n    assert candidate([100.0, 49.9]) == [1.0, 0.0]\n    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0]) == [0.0, 0.25, 0.5, 0.75, 1.0]\n    assert candidate([2.0, 1.0, 5.0, 3.0, 4.0]) == [0.25, 0.0, 1.0, 0.5, 0.75]\n    assert candidate([12.0, 11.0, 15.0, 13.0, 14.0]) == [0.25, 0.0, 1.0, 0.5, 0.75]\n", "sample_io": ["assert rescale_to_unit([1.0, 2.0, 3.0, 4.0, 5.0]) == [0.0, 0.25, 0.5, 0.75, 1.0]"], "source_codes": [""], "responses": [""], "prompt_tokens": [0], "completion_tokens": [0], "no_of_try": 1, "is_solved": false, "language": "Python3"}
{"task_id": "HumanEval/22", "prompt": "from typing import List, Any\n\n\ndef filter_integers(values: List[Any]) -> List[int]:\n    \"\"\" Filter given list of any python values only for integers\n    >>> filter_integers(['a', 3.14, 5])\n    [5]\n    >>> filter_integers([1, 2, 3, 'abc', {}, []])\n    [1, 2, 3]\n    \"\"\"\n", "entry_point": "filter_integers", "canonical_solution": "    return [x for x in values if isinstance(x, int)]\n", "test": "\n\nMETADATA = {\n    'author': 'jt',\n    'dataset': 'test'\n}\n\n\ndef check(candidate):\n    assert candidate([]) == []\n    assert candidate([4, {}, [], 23.2, 9, 'adasd']) == [4, 9]\n    assert candidate([3, 'c', 3, 3, 'a', 'b']) == [3, 3, 3]\n", "sample_io": ["assert filter_integers(['a', 3.14, 5]) == [5]", "assert filter_integers([1, 2, 3, 'abc', {}, []]) == [1, 2, 3]"], "source_codes": [""], "responses": [""], "prompt_tokens": [0], "completion_tokens": [0], "no_of_try": 1, "is_solved": false, "language": "Python3"}
{"task_id": "HumanEval/23", "prompt": "\n\ndef strlen(string: str) -> int:\n    \"\"\" Return length of given string\n    >>> strlen('')\n    0\n    >>> strlen('abc')\n    3\n    \"\"\"\n", "entry_point": "strlen", "canonical_solution": "    return len(string)\n", "test": "\n\nMETADATA = {\n    'author': 'jt',\n    'dataset': 'test'\n}\n\n\ndef check(candidate):\n    assert candidate('') == 0\n    assert candidate('x') == 1\n    assert candidate('asdasnakj') == 9\n", "sample_io": ["assert strlen('') == 0", "assert strlen('abc') == 3"], "source_codes": [""], "responses": [""], "prompt_tokens": [0], "completion_tokens": [0], "no_of_try": 1, "is_solved": false, "language": "Python3"}
{"task_id": "HumanEval/42", "prompt": "\n\ndef incr_list(l: list):\n    \"\"\"Return list with elements incremented by 1.\n    >>> incr_list([1, 2, 3])\n    [2, 3, 4]\n    >>> incr_list([5, 3, 5, 2, 3, 3, 9, 0, 123])\n    [6, 4, 6, 3, 4, 4, 10, 1, 124]\n    \"\"\"\n", "entry_point": "incr_list", "canonical_solution": "    return [(e + 1) for e in l]\n", "test": "\n\nMETADATA = {}\n\n\ndef check(candidate):\n    assert candidate([]) == []\n    assert candidate([3, 2, 1]) == [4, 3, 2]\n    assert candidate([5, 2, 5, 2, 3, 3, 9, 0, 123]) == [6, 3, 6, 3, 4, 4, 10, 1, 124]\n\n", "sample_io": ["assert incr_list([1, 2, 3]) == [2, 3, 4]", "assert incr_list([5, 3, 5, 2, 3, 3, 9, 0, 123]) == [6, 4, 6, 3, 4, 4, 10, 1, 124]"], "source_codes": ["\ndef incr_list(l: list) -> list:\n    return [x + 1 for x in l]\n\n\n"], "responses": ["\ndef incr_list(l: list) -> list:\n    return [x + 1 for x in l]\n\n\n"], "prompt_tokens": [1768], "completion_tokens": [723], "no_of_try": 1, "api_calls": 4, "is_solved": true, "language": "Python3"}
{"task_id": "HumanEval/43", "prompt": "\n\ndef pairs_sum_to_zero(l):\n    \"\"\"\n    pairs_sum_to_zero takes a list of integers as an input.\n    it returns True if there are two distinct elements in the list that\n    sum to zero, and False otherwise.\n    >>> pairs_sum_to_zero([1, 3, 5, 0])\n    False\n    >>> pairs_sum_to_zero([1, 3, -2, 1])\n    False\n    >>> pairs_sum_to_zero([1, 2, 3, 7])\n    False\n    >>> pairs_sum_to_zero([2, 4, -5, 3, 5, 7])\n    True\n    >>> pairs_sum_to_zero([1])\n    False\n    \"\"\"\n", "entry_point": "pairs_sum_to_zero", "canonical_solution": "    for i, l1 in enumerate(l):\n        for j in range(i + 1, len(l)):\n            if l1 + l[j] == 0:\n                return True\n    return False\n", "test": "\n\nMETADATA = {}\n\n\ndef check(candidate):\n    assert candidate([1, 3, 5, 0]) == False\n    assert candidate([1, 3, -2, 1]) == False\n    assert candidate([1, 2, 3, 7]) == False\n    assert candidate([2, 4, -5, 3, 5, 7]) == True\n    assert candidate([1]) == False\n\n    assert candidate([-3, 9, -1, 3, 2, 30]) == True\n    assert candidate([-3, 9, -1, 3, 2, 31]) == True\n    assert candidate([-3, 9, -1, 4, 2, 30]) == False\n    assert candidate([-3, 9, -1, 4, 2, 31]) == False\n\n", "sample_io": ["assert pairs_sum_to_zero([1, 3, 5, 0]) == False", "assert pairs_sum_to_zero([1, 3, -2, 1]) == False", "assert pairs_sum_to_zero([1, 2, 3, 7]) == False", "assert pairs_sum_to_zero([2, 4, -5, 3, 5, 7]) == True", "assert pairs_sum_to_zero([1]) == False"], "source_codes": ["\ndef pairs_sum_to_zero(l):\n    seen = set()\n    for num in l:\n        if -num in seen:\n            return True\n        seen.add(num)\n    return False\n\n\n"], "responses": ["\ndef pairs_sum_to_zero(l):\n    seen = set()\n    for num in l:\n        if -num in seen:\n            return True\n        seen.add(num)\n    return False\n\n\n"], "prompt_tokens": [1928], "completion_tokens": [878], "no_of_try": 1, "api_calls": 4, "is_solved": true, "language": "Python3"}
{"task_id": "HumanEval/44", "prompt": "\n\ndef change_base(x: int, base: int):\n    \"\"\"Change numerical base of input number x to base.\n    return string representation after the conversion.\n    base numbers are less than 10.\n    >>> change_base(8, 3)\n    '22'\n    >>> change_base(8, 2)\n    '1000'\n    >>> change_base(7, 2)\n    '111'\n    \"\"\"\n", "entry_point": "change_base", "canonical_solution": "    ret = \"\"\n    while x > 0:\n        ret = str(x % base) + ret\n        x //= base\n    return ret\n", "test": "\n\nMETADATA = {}\n\n\ndef check(candidate):\n    assert candidate(8, 3) == \"22\"\n    assert candidate(9, 3) == \"100\"\n    assert candidate(234, 2) == \"11101010\"\n    assert candidate(16, 2) == \"10000\"\n    assert candidate(8, 2) == \"1000\"\n    assert candidate(7, 2) == \"111\"\n    for x in range(2, 8):\n        assert candidate(x, x + 1) == str(x)\n\n", "sample_io": ["assert change_base(8, 3) == '22'", "assert change_base(8, 2) == '1000'", "assert change_base(7, 2) == '111'"], "source_codes": ["\ndef change_base(x: int, base: int) -> str:\n    if base >= 10:\n        raise ValueError(\"Base must be less than 10\")\n    if x == 0:\n        return '0'\n    \n    result = []\n    while x > 0:\n        remainder = x % base\n        result.append(str(remainder))\n        x //= base\n    \n    return ''.join(result[::-1])\n\n\n"], "responses": ["\ndef change_base(x: int, base: int) -> str:\n    if base >= 10:\n        raise ValueError(\"Base must be less than 10\")\n    if x == 0:\n        return '0'\n    \n    result = []\n    while x > 0:\n        remainder = x % base\n        result.append(str(remainder))\n        x //= base\n    \n    return ''.join(result[::-1])\n\n\n"], "prompt_tokens": [1875], "completion_tokens": [911], "no_of_try": 1, "api_calls": 4, "is_solved": true, "language": "Python3"}
{"task_id": "HumanEval/45", "prompt": "\n\ndef triangle_area(a, h):\n    \"\"\"Given length of a side and high return area for a triangle.\n    >>> triangle_area(5, 3)\n    7.5\n    \"\"\"\n", "entry_point": "triangle_area", "canonical_solution": "    return a * h / 2.0\n", "test": "\n\nMETADATA = {}\n\n\ndef check(candidate):\n    assert candidate(5, 3) == 7.5\n    assert candidate(2, 2) == 2.0\n    assert candidate(10, 8) == 40.0\n\n", "sample_io": ["assert triangle_area(5, 3) == 7.5"], "source_codes": ["\ndef triangle_area(a, h):\n    \"\"\"\n    Calculate the area of a triangle given the length of a side and its height.\n\n    Parameters:\n    a (float): Length of the side of the triangle.\n    h (float): Height of the triangle corresponding to the side 'a'.\n\n    Returns:\n    float: Area of the triangle.\n\n    Raises:\n    ValueError: If either the side length or height is negative.\n\n    Example:\n    >>> triangle_area(5, 3)\n    7.5\n    \"\"\"\n    if a < 0 or h < 0:\n        raise ValueError(\"Side length and height must be non-negative.\")\n    return 0.5 * a * h\n\n\n"], "responses": ["\ndef triangle_area(a, h):\n    \"\"\"\n    Calculate the area of a triangle given the length of a side and its height.\n\n    Parameters:\n    a (float): Length of the side of the triangle.\n    h (float): Height of the triangle corresponding to the side 'a'.\n\n    Returns:\n    float: Area of the triangle.\n\n    Raises:\n    ValueError: If either the side length or height is negative.\n\n    Example:\n    >>> triangle_area(5, 3)\n    7.5\n    \"\"\"\n    if a < 0 or h < 0:\n        raise ValueError(\"Side length and height must be non-negative.\")\n    return 0.5 * a * h\n\n\n"], "prompt_tokens": [1451], "completion_tokens": [844], "no_of_try": 1, "api_calls": 4, "is_solved": true, "language": "Python3"}
{"task_id": "HumanEval/46", "prompt": "\n\ndef fib4(n: int):\n    \"\"\"The Fib4 number sequence is a sequence similar to the Fibbonacci sequnece that's defined as follows:\n    fib4(0) -> 0\n    fib4(1) -> 0\n    fib4(2) -> 2\n    fib4(3) -> 0\n    fib4(n) -> fib4(n-1) + fib4(n-2) + fib4(n-3) + fib4(n-4).\n    Please write a function to efficiently compute the n-th element of the fib4 number sequence.  Do not use recursion.\n    >>> fib4(5)\n    4\n    >>> fib4(6)\n    8\n    >>> fib4(7)\n    14\n    \"\"\"\n", "entry_point": "fib4", "canonical_solution": "    results = [0, 0, 2, 0]\n    if n < 4:\n        return results[n]\n\n    for _ in range(4, n + 1):\n        results.append(results[-1] + results[-2] + results[-3] + results[-4])\n        results.pop(0)\n\n    return results[-1]\n", "test": "\n\nMETADATA = {}\n\n\ndef check(candidate):\n    assert candidate(5) == 4\n    assert candidate(8) == 28\n    assert candidate(10) == 104\n    assert candidate(12) == 386\n\n", "sample_io": ["assert fib4(5) == 4", "assert fib4(6) == 8", "assert fib4(7) == 14"], "source_codes": ["\ndef fib4(n: int) -> int:\n    if n < 4:\n        return [0, 0, 2, 0][n]\n    \n    fib4_seq = [0, 0, 2, 0]\n    for i in range(4, n + 1):\n        next_value = sum(fib4_seq[-4:])\n        fib4_seq.append(next_value)\n    \n    return fib4_seq[n]\n\n\n"], "responses": ["\ndef fib4(n: int) -> int:\n    if n < 4:\n        return [0, 0, 2, 0][n]\n    \n    fib4_seq = [0, 0, 2, 0]\n    for i in range(4, n + 1):\n        next_value = sum(fib4_seq[-4:])\n        fib4_seq.append(next_value)\n    \n    return fib4_seq[n]\n\n\n"], "prompt_tokens": [2104], "completion_tokens": [857], "no_of_try": 1, "api_calls": 4, "is_solved": true, "language": "Python3"}
{"task_id": "HumanEval/47", "prompt": "\n\ndef median(l: list):\n    \"\"\"Return median of elements in the list l.\n    >>> median([3, 1, 2, 4, 5])\n    3\n    >>> median([-10, 4, 6, 1000, 10, 20])\n    15.0\n    \"\"\"\n", "entry_point": "median", "canonical_solution": "    l = sorted(l)\n    if len(l) % 2 == 1:\n        return l[len(l) // 2]\n    else:\n        return (l[len(l) // 2 - 1] + l[len(l) // 2]) / 2.0\n", "test": "\n\nMETADATA = {}\n\n\ndef check(candidate):\n    assert candidate([3, 1, 2, 4, 5]) == 3\n    assert candidate([-10, 4, 6, 1000, 10, 20]) == 8.0\n    assert candidate([5]) == 5\n    assert candidate([6, 5]) == 5.5\n    assert candidate([8, 1, 3, 9, 9, 2, 7]) == 7 \n\n", "sample_io": ["assert median([3, 1, 2, 4, 5]) == 3", "assert median([-10, 4, 6, 1000, 10, 20]) == 15.0"], "source_codes": ["\npython\nfrom typing import List, Optional\n\ndef median(lst: List[int]) -> Optional[float]:\n    if not lst:\n        return None\n    sorted_lst = sorted(lst)\n    n = len(sorted_lst)\n    mid = n // 2\n    if n % 2 == 0:\n        return (sorted_lst[mid - 1] + sorted_lst[mid]) / 2.0\n    else:\n        return float(sorted_lst[mid])\n\n\n"], "responses": ["\npython\nfrom typing import List, Optional\n\ndef median(lst: List[int]) -> Optional[float]:\n    if not lst:\n        return None\n    sorted_lst = sorted(lst)\n    n = len(sorted_lst)\n    mid = n // 2\n    if n % 2 == 0:\n        return (sorted_lst[mid - 1] + sorted_lst[mid]) / 2.0\n    else:\n        return float(sorted_lst[mid])\n\n\n"], "prompt_tokens": [2972], "completion_tokens": [1374], "no_of_try": 1, "api_calls": 7, "is_solved": false, "language": "Python3"}
{"task_id": "HumanEval/48", "prompt": "\n\ndef is_palindrome(text: str):\n    \"\"\"\n    Checks if given string is a palindrome\n    >>> is_palindrome('')\n    True\n    >>> is_palindrome('aba')\n    True\n    >>> is_palindrome('aaaaa')\n    True\n    >>> is_palindrome('zbcd')\n    False\n    \"\"\"\n", "entry_point": "is_palindrome", "canonical_solution": "    for i in range(len(text)):\n        if text[i] != text[len(text) - 1 - i]:\n            return False\n    return True\n", "test": "\n\nMETADATA = {}\n\n\ndef check(candidate):\n    assert candidate('') == True\n    assert candidate('aba') == True\n    assert candidate('aaaaa') == True\n    assert candidate('zbcd') == False\n    assert candidate('xywyx') == True\n    assert candidate('xywyz') == False\n    assert candidate('xywzx') == False\n\n", "sample_io": ["assert is_palindrome('') == True", "assert is_palindrome('aba') == True", "assert is_palindrome('aaaaa') == True", "assert is_palindrome('zbcd') == False"], "source_codes": ["\ndef is_palindrome(text: str) -> bool:\n    left = 0\n    right = len(text) - 1\n    \n    while left < right:\n        if text[left] != text[right]:\n            return False\n        left += 1\n        right -= 1\n    \n    return True\n\n\n"], "responses": ["\ndef is_palindrome(text: str) -> bool:\n    left = 0\n    right = len(text) - 1\n    \n    while left < right:\n        if text[left] != text[right]:\n            return False\n        left += 1\n        right -= 1\n    \n    return True\n\n\n"], "prompt_tokens": [1412], "completion_tokens": [730], "no_of_try": 1, "api_calls": 4, "is_solved": true, "language": "Python3"}
{"task_id": "HumanEval/49", "prompt": "\n\ndef modp(n: int, p: int):\n    \"\"\"Return 2^n modulo p (be aware of numerics).\n    >>> modp(3, 5)\n    3\n    >>> modp(1101, 101)\n    2\n    >>> modp(0, 101)\n    1\n    >>> modp(3, 11)\n    8\n    >>> modp(100, 101)\n    1\n    \"\"\"\n", "entry_point": "modp", "canonical_solution": "    ret = 1\n    for i in range(n):\n        ret = (2 * ret) % p\n    return ret\n", "test": "\n\nMETADATA = {}\n\n\ndef check(candidate):\n    assert candidate(3, 5) == 3\n    assert candidate(1101, 101) == 2\n    assert candidate(0, 101) == 1\n    assert candidate(3, 11) == 8\n    assert candidate(100, 101) == 1\n    assert candidate(30, 5) == 4\n    assert candidate(31, 5) == 3\n\n", "sample_io": ["assert modp(3, 5) == 3", "assert modp(1101, 101) == 2", "assert modp(0, 101) == 1", "assert modp(3, 11) == 8", "assert modp(100, 101) == 1"], "source_codes": ["\ndef modp(n: int, p: int) -> int:\n    if p <= 0:\n        raise ValueError(\"Modulus must be greater than zero\")\n    if n < 0:\n        return pow(2, n % p, p)\n    result = 1\n    base = 2 % p\n    while n > 0:\n        if n % 2 == 1:\n            result = (result * base) % p\n        base = (base ** 2) % p\n        n //= 2\n    return result\n\n# Test cases\nassert modp(3, 5) == 3\nassert modp(1101, 101) == 2\nassert modp(0, 101) == 1\nassert modp(3, 11) == 8\nassert modp(100, 101) == 1\nassert modp(7, 13) == 10\nassert modp(2, 3) == 1\nassert modp(1024, 1024) == 1\nassert modp(5, 1) == 0\ntry:\n    modp(0, 0)\nexcept ValueError:\n    pass\nelse:\n    assert False, \"Expected ValueError\"\nassert modp(-3, 5) == 2\ntry:\n    modp(3, -5)\nexcept ValueError:\n    pass\nelse:\n    assert False, \"Expected ValueError\"\n\n\n"], "responses": ["\ndef modp(n: int, p: int) -> int:\n    if p <= 0:\n        raise ValueError(\"Modulus must be greater than zero\")\n    if n < 0:\n        return pow(2, n % p, p)\n    result = 1\n    base = 2 % p\n    while n > 0:\n        if n % 2 == 1:\n            result = (result * base) % p\n        base = (base ** 2) % p\n        n //= 2\n    return result\n\n# Test cases\nassert modp(3, 5) == 3\nassert modp(1101, 101) == 2\nassert modp(0, 101) == 1\nassert modp(3, 11) == 8\nassert modp(100, 101) == 1\nassert modp(7, 13) == 10\nassert modp(2, 3) == 1\nassert modp(1024, 1024) == 1\nassert modp(5, 1) == 0\ntry:\n    modp(0, 0)\nexcept ValueError:\n    pass\nelse:\n    assert False, \"Expected ValueError\"\nassert modp(-3, 5) == 2\ntry:\n    modp(3, -5)\nexcept ValueError:\n    pass\nelse:\n    assert False, \"Expected ValueError\"\n\n\n"], "prompt_tokens": [4413], "completion_tokens": [2255], "no_of_try": 1, "api_calls": 7, "is_solved": false, "language": "Python3"}
{"task_id": "HumanEval/50", "prompt": "\n\ndef encode_shift(s: str):\n    \"\"\"\n    returns encoded string by shifting every character by 5 in the alphabet.\n    \"\"\"\n    return \"\".join([chr(((ord(ch) + 5 - ord(\"a\")) % 26) + ord(\"a\")) for ch in s])\n\n\ndef decode_shift(s: str):\n    \"\"\"\n    takes as input string encoded with encode_shift function. Returns decoded string.\n    \"\"\"\n", "entry_point": "decode_shift", "canonical_solution": "    return \"\".join([chr(((ord(ch) - 5 - ord(\"a\")) % 26) + ord(\"a\")) for ch in s])\n", "test": "\n\nMETADATA = {}\n\n\ndef check(candidate):\n    from random import randint, choice\n    import copy\n    import string\n\n    letters = string.ascii_lowercase\n    for _ in range(100):\n        str = ''.join(choice(letters) for i in range(randint(10, 20)))\n        encoded_str = encode_shift(str)\n        assert candidate(copy.deepcopy(encoded_str)) == str\n\n", "sample_io": ["assert decode_shift(encode_shift('abc')) == 'abc'", "assert decode_shift(encode_shift('abcabc')) == 'abcabc'"], "source_codes": ["\ndef encode_shift(s: str):\n    \"\"\"\n    returns encoded string by shifting every character by 5 in the alphabet.\n    \"\"\"\n    return \"\".join([chr(((ord(ch) + 5 - ord(\"a\")) % 26) + ord(\"a\")) for ch in s])\n\ndef decode_shift(s: str):\n    \"\"\"\n    takes as input string encoded with encode_shift function. Returns decoded string.\n    \"\"\"\n    return \"\".join([chr(((ord(ch) - 5 - ord(\"a\")) % 26) + ord(\"a\")) if 'a' <= ch <= 'z' else ch for ch in s])\n\n\n"], "responses": ["\ndef encode_shift(s: str):\n    \"\"\"\n    returns encoded string by shifting every character by 5 in the alphabet.\n    \"\"\"\n    return \"\".join([chr(((ord(ch) + 5 - ord(\"a\")) % 26) + ord(\"a\")) for ch in s])\n\ndef decode_shift(s: str):\n    \"\"\"\n    takes as input string encoded with encode_shift function. Returns decoded string.\n    \"\"\"\n    return \"\".join([chr(((ord(ch) - 5 - ord(\"a\")) % 26) + ord(\"a\")) if 'a' <= ch <= 'z' else ch for ch in s])\n\n\n"], "prompt_tokens": [1217], "completion_tokens": [654], "no_of_try": 1, "api_calls": 4, "is_solved": true, "language": "Python3"}
{"task_id": "HumanEval/51", "prompt": "\n\ndef remove_vowels(text):\n    \"\"\"\n    remove_vowels is a function that takes string and returns string without vowels.\n    >>> remove_vowels('')\n    ''\n    >>> remove_vowels(\"abcdef\\nghijklm\")\n    'bcdf\\nghjklm'\n    >>> remove_vowels('abcdef')\n    'bcdf'\n    >>> remove_vowels('aaaaa')\n    ''\n    >>> remove_vowels('aaBAA')\n    'B'\n    >>> remove_vowels('zbcd')\n    'zbcd'\n    \"\"\"\n", "entry_point": "remove_vowels", "canonical_solution": "    return \"\".join([s for s in text if s.lower() not in [\"a\", \"e\", \"i\", \"o\", \"u\"]])\n", "test": "\n\nMETADATA = {}\n\n\ndef check(candidate):\n    assert candidate('') == ''\n    assert candidate(\"abcdef\\nghijklm\") == 'bcdf\\nghjklm'\n    assert candidate('fedcba') == 'fdcb'\n    assert candidate('eeeee') == ''\n    assert candidate('acBAA') == 'cB'\n    assert candidate('EcBOO') == 'cB'\n    assert candidate('ybcd') == 'ybcd'\n\n", "sample_io": ["assert remove_vowels('') == ''", "assert remove_vowels(\"abcdef\\nghijklm\") == 'bcdf\\nghjklm'", "assert remove_vowels('abcdef') == 'bcdf'", "assert remove_vowels('aaaaa') == ''", "assert remove_vowels('aaBAA') == 'B'", "assert remove_vowels('zbcd') == 'zbcd'"], "source_codes": ["\ndef remove_vowels(text):\n    \"\"\"\n    remove_vowels is a function that takes string and returns string without vowels.\n    \"\"\"\n    vowels = \"aeiouAEIOU\"\n    result = ''.join([char for char in text if char not in vowels])\n    return result\n\n\n"], "responses": ["\ndef remove_vowels(text):\n    \"\"\"\n    remove_vowels is a function that takes string and returns string without vowels.\n    \"\"\"\n    vowels = \"aeiouAEIOU\"\n    result = ''.join([char for char in text if char not in vowels])\n    return result\n\n\n"], "prompt_tokens": [1660], "completion_tokens": [589], "no_of_try": 1, "api_calls": 4, "is_solved": true, "language": "Python3"}
{"task_id": "HumanEval/52", "prompt": "\n\ndef below_threshold(l: list, t: int):\n    \"\"\"Return True if all numbers in the list l are below threshold t.\n    >>> below_threshold([1, 2, 4, 10], 100)\n    True\n    >>> below_threshold([1, 20, 4, 10], 5)\n    False\n    \"\"\"\n", "entry_point": "below_threshold", "canonical_solution": "    for e in l:\n        if e >= t:\n            return False\n    return True\n", "test": "\n\nMETADATA = {}\n\n\ndef check(candidate):\n    assert candidate([1, 2, 4, 10], 100)\n    assert not candidate([1, 20, 4, 10], 5)\n    assert candidate([1, 20, 4, 10], 21)\n    assert candidate([1, 20, 4, 10], 22)\n    assert candidate([1, 8, 4, 10], 11)\n    assert not candidate([1, 8, 4, 10], 10)\n\n", "sample_io": ["assert below_threshold([1, 2, 4, 10], 100) == True", "assert below_threshold([1, 20, 4, 10], 5) == False"], "source_codes": ["\ndef below_threshold(l: list, t: int) -> bool:\n    for num in l:\n        if num >= t:\n            return False\n    return True\n\n\n"], "responses": ["\ndef below_threshold(l: list, t: int) -> bool:\n    for num in l:\n        if num >= t:\n            return False\n    return True\n\n\n"], "prompt_tokens": [1673], "completion_tokens": [690], "no_of_try": 1, "api_calls": 4, "is_solved": true, "language": "Python3"}
{"task_id": "HumanEval/53", "prompt": "\n\ndef add(x: int, y: int):\n    \"\"\"Add two numbers x and y\n    >>> add(2, 3)\n    5\n    >>> add(5, 7)\n    12\n    \"\"\"\n", "entry_point": "add", "canonical_solution": "    return x + y\n", "test": "\n\nMETADATA = {}\n\n\ndef check(candidate):\n    import random\n\n    assert candidate(0, 1) == 1\n    assert candidate(1, 0) == 1\n    assert candidate(2, 3) == 5\n    assert candidate(5, 7) == 12\n    assert candidate(7, 5) == 12\n\n    for i in range(100):\n        x, y = random.randint(0, 1000), random.randint(0, 1000)\n        assert candidate(x, y) == x + y\n\n", "sample_io": ["assert add(2, 3) == 5", "assert add(5, 7) == 12"], "source_codes": ["\ndef add(x: int, y: int) -> int:\n    \"\"\"Add two numbers x and y\n    \n    Parameters:\n    x (int): The first number.\n    y (int): The second number.\n    \n    Returns:\n    int: The sum of x and y.\n    \n    Examples:\n    >>> add(2, 3)\n    5\n    >>> add(5, 7)\n    12\n    \"\"\"\n    return x + y\n\n\n"], "responses": ["\ndef add(x: int, y: int) -> int:\n    \"\"\"Add two numbers x and y\n    \n    Parameters:\n    x (int): The first number.\n    y (int): The second number.\n    \n    Returns:\n    int: The sum of x and y.\n    \n    Examples:\n    >>> add(2, 3)\n    5\n    >>> add(5, 7)\n    12\n    \"\"\"\n    return x + y\n\n\n"], "prompt_tokens": [1377], "completion_tokens": [724], "no_of_try": 1, "api_calls": 4, "is_solved": true, "language": "Python3"}
{"task_id": "HumanEval/54", "prompt": "\n\ndef same_chars(s0: str, s1: str):\n    \"\"\"\n    Check if two words have the same characters.\n    >>> same_chars('eabcdzzzz', 'dddzzzzzzzddeddabc')\n    True\n    >>> same_chars('abcd', 'dddddddabc')\n    True\n    >>> same_chars('dddddddabc', 'abcd')\n    True\n    >>> same_chars('eabcd', 'dddddddabc')\n    False\n    >>> same_chars('abcd', 'dddddddabce')\n    False\n    >>> same_chars('eabcdzzzz', 'dddzzzzzzzddddabc')\n    False\n    \"\"\"\n", "entry_point": "same_chars", "canonical_solution": "    return set(s0) == set(s1)\n", "test": "\n\nMETADATA = {}\n\n\ndef check(candidate):\n    assert candidate('eabcdzzzz', 'dddzzzzzzzddeddabc') == True\n    assert candidate('abcd', 'dddddddabc') == True\n    assert candidate('dddddddabc', 'abcd') == True\n    assert candidate('eabcd', 'dddddddabc') == False\n    assert candidate('abcd', 'dddddddabcf') == False\n    assert candidate('eabcdzzzz', 'dddzzzzzzzddddabc') == False\n    assert candidate('aabb', 'aaccc') == False\n\n", "sample_io": ["assert same_chars('eabcdzzzz', 'dddzzzzzzzddeddabc') == True", "assert same_chars('abcd', 'dddddddabc') == True", "assert same_chars('dddddddabc', 'abcd') == True", "assert same_chars('eabcd', 'dddddddabc') == False", "assert same_chars('abcd', 'dddddddabce') == False", "assert same_chars('eabcdzzzz', 'dddzzzzzzzddddabc') == False"], "source_codes": ["\npython\ndef same_chars(s0: str, s1: str) -> bool:\n    \"\"\"\n    Check if two words have the same characters.\n    \"\"\"\n\n    # Initialize frequency counters for both input strings using dictionaries\n    freq_counter_s0 = {}\n    freq_counter_s1 = {}\n\n    # Populate frequency counter for the first string\n    for char in s0:\n        freq_counter_s0[char] = freq_counter_s0.get(char, 0) + 1\n\n    # Populate frequency counter for the second string\n    for char in s1:\n        freq_counter_s1[char] = freq_counter_s1.get(char, 0) + 1\n\n    # Compare the frequency counters\n    if freq_counter_s0 == freq_counter_s1:\n        return True\n    else:\n        return False\n\n\n"], "responses": ["\npython\ndef same_chars(s0: str, s1: str) -> bool:\n    \"\"\"\n    Check if two words have the same characters.\n    \"\"\"\n\n    # Initialize frequency counters for both input strings using dictionaries\n    freq_counter_s0 = {}\n    freq_counter_s1 = {}\n\n    # Populate frequency counter for the first string\n    for char in s0:\n        freq_counter_s0[char] = freq_counter_s0.get(char, 0) + 1\n\n    # Populate frequency counter for the second string\n    for char in s1:\n        freq_counter_s1[char] = freq_counter_s1.get(char, 0) + 1\n\n    # Compare the frequency counters\n    if freq_counter_s0 == freq_counter_s1:\n        return True\n    else:\n        return False\n\n\n"], "prompt_tokens": [3867], "completion_tokens": [1198], "no_of_try": 1, "api_calls": 7, "is_solved": false, "language": "Python3"}
{"task_id": "HumanEval/55", "prompt": "\n\ndef fib(n: int):\n    \"\"\"Return n-th Fibonacci number.\n    >>> fib(10)\n    55\n    >>> fib(1)\n    1\n    >>> fib(8)\n    21\n    \"\"\"\n", "entry_point": "fib", "canonical_solution": "    if n == 0:\n        return 0\n    if n == 1:\n        return 1\n    return fib(n - 1) + fib(n - 2)\n", "test": "\n\nMETADATA = {}\n\n\ndef check(candidate):\n    assert candidate(10) == 55\n    assert candidate(1) == 1\n    assert candidate(8) == 21\n    assert candidate(11) == 89\n    assert candidate(12) == 144\n\n", "sample_io": ["assert fib(10) == 55", "assert fib(1) == 1", "assert fib(8) == 21"], "source_codes": ["\nfrom functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib(n: int) -> int:\n    if n < 0:\n        raise ValueError(\"Input must be a non-negative integer\")\n    elif n == 0:\n        return 0\n    elif n == 1:\n        return 1\n    else:\n        return fib(n - 1) + fib(n - 2)\n\n# Test cases\nassert fib(10) == 55\nassert fib(1) == 1\nassert fib(8) == 21\ntry:\n    assert fib(-1) == 55\nexcept ValueError:\n    pass\nassert fib(0) == 0\n\n\n"], "responses": ["\nfrom functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib(n: int) -> int:\n    if n < 0:\n        raise ValueError(\"Input must be a non-negative integer\")\n    elif n == 0:\n        return 0\n    elif n == 1:\n        return 1\n    else:\n        return fib(n - 1) + fib(n - 2)\n\n# Test cases\nassert fib(10) == 55\nassert fib(1) == 1\nassert fib(8) == 21\ntry:\n    assert fib(-1) == 55\nexcept ValueError:\n    pass\nassert fib(0) == 0\n\n\n"], "prompt_tokens": [1256], "completion_tokens": [952], "no_of_try": 1, "api_calls": 4, "is_solved": true, "language": "Python3"}
{"task_id": "HumanEval/56", "prompt": "\n\ndef correct_bracketing(brackets: str):\n    \"\"\" brackets is a string of \"<\" and \">\".\n    return True if every opening bracket has a corresponding closing bracket.\n\n    >>> correct_bracketing(\"<\")\n    False\n    >>> correct_bracketing(\"<>\")\n    True\n    >>> correct_bracketing(\"<<><>>\")\n    True\n    >>> correct_bracketing(\"><<>\")\n    False\n    \"\"\"\n", "entry_point": "correct_bracketing", "canonical_solution": "    depth = 0\n    for b in brackets:\n        if b == \"<\":\n            depth += 1\n        else:\n            depth -= 1\n        if depth < 0:\n            return False\n    return depth == 0\n", "test": "\n\nMETADATA = {}\n\n\ndef check(candidate):\n    assert candidate(\"<>\")\n    assert candidate(\"<<><>>\")\n    assert candidate(\"<><><<><>><>\")\n    assert candidate(\"<><><<<><><>><>><<><><<>>>\")\n    assert not candidate(\"<<<><>>>>\")\n    assert not candidate(\"><<>\")\n    assert not candidate(\"<\")\n    assert not candidate(\"<<<<\")\n    assert not candidate(\">\")\n    assert not candidate(\"<<>\")\n    assert not candidate(\"<><><<><>><>><<>\")\n    assert not candidate(\"<><><<><>><>>><>\")\n\n", "sample_io": ["assert correct_bracketing(\"<\") == False", "correct_bracketing(\"<>\") == True", "correct_bracketing(\"<<><>>\") == True", "correct_bracketing(\"><<>\") == False"], "source_codes": ["\ndef correct_bracketing(brackets: str) -> bool:\n    balance = 0\n    for bracket in brackets:\n        if bracket == '<':\n            balance += 1\n        elif bracket == '>':\n            balance -= 1\n        if balance < 0:\n            return False\n    return balance == 0\n\n\n"], "responses": ["\ndef correct_bracketing(brackets: str) -> bool:\n    balance = 0\n    for bracket in brackets:\n        if bracket == '<':\n            balance += 1\n        elif bracket == '>':\n            balance -= 1\n        if balance < 0:\n            return False\n    return balance == 0\n\n\n"], "prompt_tokens": [791], "completion_tokens": [987], "no_of_try": 1, "api_calls": 4, "is_solved": true, "language": "Python3"}
{"task_id": "HumanEval/57", "prompt": "\n\ndef monotonic(l: list):\n    \"\"\"Return True is list elements are monotonically increasing or decreasing.\n    >>> monotonic([1, 2, 4, 20])\n    True\n    >>> monotonic([1, 20, 4, 10])\n    False\n    >>> monotonic([4, 1, 0, -10])\n    True\n    \"\"\"\n", "entry_point": "monotonic", "canonical_solution": "    if l == sorted(l) or l == sorted(l, reverse=True):\n        return True\n    return False\n", "test": "\n\nMETADATA = {}\n\n\ndef check(candidate):\n    assert candidate([1, 2, 4, 10]) == True\n    assert candidate([1, 2, 4, 20]) == True\n    assert candidate([1, 20, 4, 10]) == False\n    assert candidate([4, 1, 0, -10]) == True\n    assert candidate([4, 1, 1, 0]) == True\n    assert candidate([1, 2, 3, 2, 5, 60]) == False\n    assert candidate([1, 2, 3, 4, 5, 60]) == True\n    assert candidate([9, 9, 9, 9]) == True\n\n", "sample_io": ["assert monotonic([1, 2, 4, 20]) == True", "assert monotonic([1, 20, 4, 10]) == False", "assert monotonic([4, 1, 0, -10]) == True"], "source_codes": ["\ndef monotonic(l: list) -> bool:\n    if len(l) <= 1:\n        return True\n    increasing = decreasing = True\n    for i in range(len(l) - 1):\n        if l[i] < l[i + 1]:\n            decreasing = False\n        elif l[i] > l[i + 1]:\n            increasing = False\n    return increasing or decreasing\n\n\n"], "responses": ["\ndef monotonic(l: list) -> bool:\n    if len(l) <= 1:\n        return True\n    increasing = decreasing = True\n    for i in range(len(l) - 1):\n        if l[i] < l[i + 1]:\n            decreasing = False\n        elif l[i] > l[i + 1]:\n            increasing = False\n    return increasing or decreasing\n\n\n"], "prompt_tokens": [1875], "completion_tokens": [829], "no_of_try": 1, "api_calls": 4, "is_solved": true, "language": "Python3"}
{"task_id": "HumanEval/58", "prompt": "\n\ndef common(l1: list, l2: list):\n    \"\"\"Return sorted unique common elements for two lists.\n    >>> common([1, 4, 3, 34, 653, 2, 5], [5, 7, 1, 5, 9, 653, 121])\n    [1, 5, 653]\n    >>> common([5, 3, 2, 8], [3, 2])\n    [2, 3]\n\n    \"\"\"\n", "entry_point": "common", "canonical_solution": "    ret = set()\n    for e1 in l1:\n        for e2 in l2:\n            if e1 == e2:\n                ret.add(e1)\n    return sorted(list(ret))\n", "test": "\n\nMETADATA = {}\n\n\ndef check(candidate):\n    assert candidate([1, 4, 3, 34, 653, 2, 5], [5, 7, 1, 5, 9, 653, 121]) == [1, 5, 653]\n    assert candidate([5, 3, 2, 8], [3, 2]) == [2, 3]\n    assert candidate([4, 3, 2, 8], [3, 2, 4]) == [2, 3, 4]\n    assert candidate([4, 3, 2, 8], []) == []\n\n", "sample_io": ["assert common([1, 4, 3, 34, 653, 2, 5], [5, 7, 1, 5, 9, 653, 121]) == [1, 5, 653]", "assert common([5, 3, 2, 8], [3, 2]) == [2, 3]"], "source_codes": ["\ndef common(l1: list, l2: list) -> list:\n    set1 = set(l1)\n    set2 = set(l2)\n    common_elements = set1.intersection(set2)\n    return sorted(list(common_elements))\n\n\n"], "responses": ["\ndef common(l1: list, l2: list) -> list:\n    set1 = set(l1)\n    set2 = set(l2)\n    common_elements = set1.intersection(set2)\n    return sorted(list(common_elements))\n\n\n"], "prompt_tokens": [1865], "completion_tokens": [810], "no_of_try": 1, "api_calls": 4, "is_solved": true, "language": "Python3"}
{"task_id": "HumanEval/59", "prompt": "\n\ndef largest_prime_factor(n: int):\n    \"\"\"Return the largest prime factor of n. Assume n > 1 and is not a prime.\n    >>> largest_prime_factor(13195)\n    29\n    >>> largest_prime_factor(2048)\n    2\n    \"\"\"\n", "entry_point": "largest_prime_factor", "canonical_solution": "    def is_prime(k):\n        if k < 2:\n            return False\n        for i in range(2, k - 1):\n            if k % i == 0:\n                return False\n        return True\n    largest = 1\n    for j in range(2, n + 1):\n        if n % j == 0 and is_prime(j):\n            largest = max(largest, j)\n    return largest\n", "test": "\n\nMETADATA = {}\n\n\ndef check(candidate):\n    assert candidate(15) == 5\n    assert candidate(27) == 3\n    assert candidate(63) == 7\n    assert candidate(330) == 11\n    assert candidate(13195) == 29\n\n", "sample_io": ["assert largest_prime_factor(13195) == 29", "assert largest_prime_factor(2048) == 2"], "source_codes": ["\nimport math\n\ndef largest_prime_factor(n: int) -> int:\n    largest_factor = 1\n    while n % 2 == 0:\n        largest_factor = 2\n        n //= 2\n    \n    for i in range(3, int(math.sqrt(n)) + 1, 2):\n        while n % i == 0:\n            largest_factor = i\n            n //= i\n    \n    if n > 2:\n        largest_factor = n\n    \n    return largest_factor\n\n\n"], "responses": ["\nimport math\n\ndef largest_prime_factor(n: int) -> int:\n    largest_factor = 1\n    while n % 2 == 0:\n        largest_factor = 2\n        n //= 2\n    \n    for i in range(3, int(math.sqrt(n)) + 1, 2):\n        while n % i == 0:\n            largest_factor = i\n            n //= i\n    \n    if n > 2:\n        largest_factor = n\n    \n    return largest_factor\n\n\n"], "prompt_tokens": [1793], "completion_tokens": [1022], "no_of_try": 1, "api_calls": 4, "is_solved": true, "language": "Python3"}
{"task_id": "HumanEval/60", "prompt": "\n\ndef sum_to_n(n: int):\n    \"\"\"sum_to_n is a function that sums numbers from 1 to n.\n    >>> sum_to_n(30)\n    465\n    >>> sum_to_n(100)\n    5050\n    >>> sum_to_n(5)\n    15\n    >>> sum_to_n(10)\n    55\n    >>> sum_to_n(1)\n    1\n    \"\"\"\n", "entry_point": "sum_to_n", "canonical_solution": "    return sum(range(n + 1))\n", "test": "\n\nMETADATA = {}\n\n\ndef check(candidate):\n    assert candidate(1) == 1\n    assert candidate(6) == 21\n    assert candidate(11) == 66\n    assert candidate(30) == 465\n    assert candidate(100) == 5050\n\n", "sample_io": ["assert sum_to_n(30) == 465", "assert sum_to_n(100) == 5050", "assert sum_to_n(5) == 15", "assert sum_to_n(10) == 55", "assert sum_to_n(1) == 1"], "source_codes": ["\ndef sum_to_n(n: int) -> int:\n    if n < 1:\n        return None\n    return n * (n + 1) // 2\n\n\n"], "responses": ["\ndef sum_to_n(n: int) -> int:\n    if n < 1:\n        return None\n    return n * (n + 1) // 2\n\n\n"], "prompt_tokens": [1857], "completion_tokens": [977], "no_of_try": 1, "api_calls": 4, "is_solved": true, "language": "Python3"}
{"task_id": "HumanEval/61", "prompt": "\n\ndef correct_bracketing(brackets: str):\n    \"\"\" brackets is a string of \"(\" and \")\".\n    return True if every opening bracket has a corresponding closing bracket.\n\n    >>> correct_bracketing(\"(\")\n    False\n    >>> correct_bracketing(\"()\")\n    True\n    >>> correct_bracketing(\"(()())\")\n    True\n    >>> correct_bracketing(\")(()\")\n    False\n    \"\"\"\n", "entry_point": "correct_bracketing", "canonical_solution": "    depth = 0\n    for b in brackets:\n        if b == \"(\":\n            depth += 1\n        else:\n            depth -= 1\n        if depth < 0:\n            return False\n    return depth == 0\n", "test": "\n\nMETADATA = {}\n\n\ndef check(candidate):\n    assert candidate(\"()\")\n    assert candidate(\"(()())\")\n    assert candidate(\"()()(()())()\")\n    assert candidate(\"()()((()()())())(()()(()))\")\n    assert not candidate(\"((()())))\")\n    assert not candidate(\")(()\")\n    assert not candidate(\"(\")\n    assert not candidate(\"((((\")\n    assert not candidate(\")\")\n    assert not candidate(\"(()\")\n    assert not candidate(\"()()(()())())(()\")\n    assert not candidate(\"()()(()())()))()\")\n\n", "sample_io": ["assert correct_bracketing(\"(\") == False", "correct_bracketing(\"()\") == True", "correct_bracketing(\"(()())\") == True", "correct_bracketing(\")(()\") == False"], "source_codes": ["\ndef correct_bracketing(brackets: str) -> bool:\n    stack = []\n    \n    for bracket in brackets:\n        if bracket == '(':\n            stack.append(bracket)\n        elif bracket == ')':\n            if not stack:\n                return False\n            stack.pop()\n    \n    return len(stack) == 0\n\n\n"], "responses": ["\ndef correct_bracketing(brackets: str) -> bool:\n    stack = []\n    \n    for bracket in brackets:\n        if bracket == '(':\n            stack.append(bracket)\n        elif bracket == ')':\n            if not stack:\n                return False\n            stack.pop()\n    \n    return len(stack) == 0\n\n\n"], "prompt_tokens": [1727], "completion_tokens": [994], "no_of_try": 1, "api_calls": 4, "is_solved": true, "language": "Python3"}
{"task_id": "HumanEval/62", "prompt": "\n\ndef derivative(xs: list):\n    \"\"\" xs represent coefficients of a polynomial.\n    xs[0] + xs[1] * x + xs[2] * x^2 + ....\n     Return derivative of this polynomial in the same form.\n    >>> derivative([3, 1, 2, 4, 5])\n    [1, 4, 12, 20]\n    >>> derivative([1, 2, 3])\n    [2, 6]\n    \"\"\"\n", "entry_point": "derivative", "canonical_solution": "    return [(i * x) for i, x in enumerate(xs)][1:]\n", "test": "\n\nMETADATA = {}\n\n\ndef check(candidate):\n    assert candidate([3, 1, 2, 4, 5]) == [1, 4, 12, 20]\n    assert candidate([1, 2, 3]) == [2, 6]\n    assert candidate([3, 2, 1]) == [2, 2]\n    assert candidate([3, 2, 1, 0, 4]) == [2, 2, 0, 16]\n    assert candidate([1]) == []\n\n", "sample_io": ["assert derivative([3, 1, 2, 4, 5]) == [1, 4, 12, 20]", "assert derivative([1, 2, 3]) == [2, 6]"], "source_codes": ["\ndef derivative(xs: list):\n    return [i * xs[i] for i in range(1, len(xs))]\n\n\n"], "responses": ["\ndef derivative(xs: list):\n    return [i * xs[i] for i in range(1, len(xs))]\n\n\n"], "prompt_tokens": [1660], "completion_tokens": [680], "no_of_try": 1, "api_calls": 4, "is_solved": true, "language": "Python3"}
